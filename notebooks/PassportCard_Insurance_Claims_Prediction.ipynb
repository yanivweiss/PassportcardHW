{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PassportCard Insurance Claims Prediction\n\nThis project develops a machine learning system to predict future insurance claims for PassportCard policyholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n\nFirst, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn xgboost lightgbm jupyter scipy statsmodels plotly imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import xgboost as xgb\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n\nLet's load the claims and member data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load claims data\n",
    "claims_data = pd.read_csv('claims_data_clean.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Claims data shape: {claims_data.shape}\")\n",
    "claims_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load member data\n",
    "members_data = pd.read_csv('members_data_clean.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Members data shape: {members_data.shape}\")\n",
    "members_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning\n\nLet's explore the data and perform necessary cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "claims_data['ServiceDate'] = pd.to_datetime(claims_data['ServiceDate'])\n",
    "claims_data['PayDate'] = pd.to_datetime(claims_data['PayDate'])\n",
    "\n",
    "# Display basic statistics\n",
    "claims_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of claim amounts\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Main plot - histogram with KDE\n",
    "sns.histplot(claims_data['TotPaymentUSD'], kde=True, bins=50)\n",
    "plt.title('Distribution of Claim Amounts (TotPaymentUSD)', fontsize=16)\n",
    "plt.xlabel('Claim Amount (USD)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "# Add statistical annotations\n",
    "mean_val = claims_data['TotPaymentUSD'].mean()\n",
    "median_val = claims_data['TotPaymentUSD'].median()\n",
    "skew_val = claims_data['TotPaymentUSD'].skew()\n",
    "kurtosis_val = claims_data['TotPaymentUSD'].kurtosis()\n",
    "\n",
    "stats_text = f\"Mean: ${mean_val:.2f}\\nMedian: ${median_val:.2f}\\nSkewness: {skew_val:.2f}\\nKurtosis: {kurtosis_val:.2f}\"\n",
    "plt.annotate(stats_text, xy=(0.75, 0.75), xycoords='axes fraction', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Analysis and Data Cleaning\n\nLet's analyze missing values and handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, categorical_strategy='mode', numerical_strategy='knn'):\n",
    "    \"\"\"Advanced missing value handling with multiple strategies\"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Get column types\n",
    "    categorical_cols = df_processed.select_dtypes(include=['object', 'category']).columns\n",
    "    numerical_cols = df_processed.select_dtypes(include=['int', 'float']).columns\n",
    "    \n",
    "    # Handle categorical features\n",
    "    for col in categorical_cols:\n",
    "        missing_count = df_processed[col].isna().sum()\n",
    "        if missing_count > 0:\n",
    "            print(f\"Column {col}: {missing_count} missing values ({missing_count/len(df_processed)*100:.2f}%)\")\n",
    "            \n",
    "            if categorical_strategy == 'mode':\n",
    "                # Replace with mode\n",
    "                mode_value = df_processed[col].mode()[0]\n",
    "                df_processed[col].fillna(mode_value, inplace=True)\n",
    "                print(f\"  - Filled with mode: {mode_value}\")\n",
    "    \n",
    "    # Handle numerical features\n",
    "    if numerical_strategy == 'knn':\n",
    "        # Check if there are any missing numerical values\n",
    "        num_missing = df_processed[numerical_cols].isna().sum().sum()\n",
    "        if num_missing > 0:\n",
    "            print(f\"Using KNN imputation for {num_missing} missing numerical values\")\n",
    "            \n",
    "            # Use KNN imputation for numerical features\n",
    "            numerical_data = df_processed[numerical_cols]\n",
    "            \n",
    "            # Handle infinite values before KNN imputation\n",
    "            numerical_data = numerical_data.replace([np.inf, -np.inf], np.nan)\n",
    "            \n",
    "            # Initialize and fit the KNN imputer\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            imputed_data = imputer.fit_transform(numerical_data)\n",
    "            \n",
    "            # Update the dataframe with imputed values\n",
    "            df_processed[numerical_cols] = imputed_data\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Apply the function to our datasets\n",
    "claims_data_clean = handle_missing_values(claims_data)\n",
    "members_data_clean = handle_missing_values(members_data)\n",
    "\n",
    "# Verify that all missing values are handled\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(f\"Claims data: {claims_data_clean.isnull().sum().sum()}\")\n",
    "print(f\"Members data: {members_data_clean.isnull().sum().sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}